{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "homeless-costs",
   "metadata": {},
   "source": [
    "# Creating a new dataset\n",
    "In this notebook we will have a look at creating a new dataset from a set of records. First we will take a look a the result of a training, make a selection based on the results and than train on the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import panel as pn\n",
    "\n",
    "from icevision.all import *\n",
    "import icedata\n",
    "from icevision_dashboards.dashboards import *\n",
    "from icevision_dashboards.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.extension()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-pursuit",
   "metadata": {},
   "source": [
    "# Look at training results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainings_results = ObjectDetectionResultsDataset.load(\"test_data/fridge_example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-september",
   "metadata": {},
   "source": [
    "If we take a look at the data below we can see that the model works better on images with only one annoation. Furthermore we can see, that the score distribution that the model is much more confident in some classes. (Here the reason is that the training was stopped before it could converge). Lets say we now want to create a subset and train a model on the subset, where the number of annotations equals 1 and we want to use the following classes Pug, Shiba Inu, Great Pyrenees ans Sphynx. We can use the `ObjectDetectionDatasetGenerator` dashboard to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainings_resuls_overivew = ObjectDetectionResultOverview(trainings_results)\n",
    "trainings_resuls_overivew.show_loss_tab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-fellowship",
   "metadata": {},
   "source": [
    "# Create a subdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data and class_map\n",
    "path = icedata.fridge.load_data()\n",
    "class_map = icedata.fridge.class_map()\n",
    "\n",
    "# use the provided dataset parser\n",
    "parser = icedata.fridge.parser(data_dir=path)\n",
    "records = parser.parse(RandomSplitter([1]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset the can be consumed by a dashboard\n",
    "dash_ds = BboxRecordDataset(records, class_map=class_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-judges",
   "metadata": {},
   "source": [
    "First select the ranges with the range silder than select the classes you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "dash_generator = ObjectDetectionDatasetGeneratorRange(dash_ds, width=1000, height=700)\n",
    "dash_generator.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the created dataset\n",
    "new_dataset = BboxRecordDataset(\"datasets/dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick overview of the dataset\n",
    "ObjectDetectionDatasetOverview(new_dataset, height=700, width=1000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the records into a training and test dataset\n",
    "train_records, valid_records = new_dataset.split_in_train_and_val(0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-joyce",
   "metadata": {},
   "source": [
    "## Train a model on the new Dataset\n",
    "Now that we have the new dataset we can train a model on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms\n",
    "train_tfms = tfms.A.Adapter(\n",
    "    [*tfms.A.aug_tfms(size=384, presize=512), tfms.A.Normalize()]\n",
    ")\n",
    "valid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(384), tfms.A.Normalize()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the datasets and dataloaders\n",
    "train_ds = Dataset(train_records, train_tfms)\n",
    "valid_ds = Dataset(valid_records, valid_tfms)\n",
    "\n",
    "train_dl = faster_rcnn.train_dl(train_ds, batch_size=8, num_workers=4, shuffle=True)\n",
    "valid_dl = faster_rcnn.valid_dl(valid_ds, batch_size=8, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model and train it for some epochs\n",
    "model = faster_rcnn.model(num_classes=len(new_dataset.class_map))\n",
    "\n",
    "learn = faster_rcnn.fastai.learner(dls=[train_dl, valid_dl], model=model)\n",
    "\n",
    "learn.fine_tune(5, base_lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_plus_losses, preds, losses_stats = faster_rcnn.interp.plot_top_losses(model=model, dataset=valid_ds, sort_by=\"loss_total\", n_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset that can be consumed by the analysis dashboard\n",
    "valid_result_ds = ObjectDetectionResultsDataset.init_from_preds_and_samples(preds, samples_plus_losses, class_map=class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dashboard\n",
    "result_overview_dash = ObjectDetectionResultOverview(valid_result_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the loss tab\n",
    "result_overview_dash.show_loss_tab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the ap tab\n",
    "result_overview_dash.show_ap_tab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-portable",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
